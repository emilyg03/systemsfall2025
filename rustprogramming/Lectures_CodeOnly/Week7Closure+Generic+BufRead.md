

// Example #1 Read whole file: What is a problem?

use std::io;
fn read_whole_file(file_paths: &[&str]) -> io::Result<()>{
    use std::time::Instant;
    use std::fs::File;
    use std::io::Read;

    
    let start = Instant::now();

    for &file_path in file_paths {
        let mut file = File::open(file_path)?;
        let mut contents = String::new();
        file.read_to_string(&mut contents)?;
    }

    let direct_duration = start.elapsed();
    println!("Direct read duration: {:?}", direct_duration);


    Ok(())
    
}

// In this example, read_to_string is used to read the entire contents of the file into a String 
// in one operation. This is simple and works well for small files, 
// but it can be memory-intensive and slower for large files, as it requires loading the entire 
// file into memory at once. Additionally, this approach doesn't lend itself 
// as well to scenarios where you want to process a file incrementally without holding everything in memory.


fn buffered_reader(file_paths: &[&str]) -> io::Result<()> {
    use std::time::Instant;
    use std::fs::File;
    use std::io::BufRead; // Trait
    use std::io::BufReader; // Struct
    use std::io::Read;

    let start = Instant::now();

    for &file_path in file_paths {
        let file = File::open(file_path)?;
        let mut reader = BufReader::new(file);
        let mut contents = Vec::new();

        // Read the entire contents into a vector without parsing lines
        reader.read_to_end(&mut contents)?;
    }

    let buffered_duration = start.elapsed();
    println!("Buffered read duration: {:?}", buffered_duration);

    Ok(())

}



fn main(){
    let files = vec!["file1.txt", "file2.txt", "file3.txt"]; 
    let _ = read_whole_file(&files);
    let _ = buffered_reader(&files);

    // wget link_to_file


    // for i in {1..1000}; do cat pg73256.txt >> large_file.txt; done

    let files = vec!["large_file.txt"]; 
    let _ = read_whole_file(&files);
    let _ = buffered_reader(&files);

    
    // my result of cargo run
    // Direct read duration: 719.531µs
    // Buffered read duration: 117.479µs
    // Direct read duration: 1.546058925s
    // Buffered read duration: 1.252805657s

    // my result cargo run --release

    // Direct read duration: 727.022µs
    // Buffered read duration: 248.263µs
    // Direct read duration: 1.91002664s
    // Buffered read duration: 1.07272962s

}


BufRead
BufRead is a trait that represents the ability to read from a buffered input stream.

BufReader
BufReader is a struct that implements the BufRead and Read traits, providing an efficient buffered reader that wraps around another reader type. It's typically used to wrap unbuffered readers like File, adding a layer of buffering to improve read performance. By reading data in larger chunks into a buffer and then providing access to this buffer, BufReader reduces the number of read calls needed, which can significantly improve performance when reading from slow sources like files or network streams.









Scenario: Efficiently Processing Log Files
Imagine you're developing a part of a system monitor tool in Rust that needs to process log files generated by various system services. These log files can be large, and you need to extract certain information efficiently, such as error messages, without loading the entire file into memory. Additionally, the criteria for what constitutes an interesting log entry (e.g., an error vs. a warning) might change depending on the system's state or user input.

For this task, you could write a function that processes a log file line by line and accepts a closure as a parameter. This closure can encapsulate the logic for deciding whether a given line is of interest, allowing the caller to specify what they're looking for in the logs dynamically.

Example: Filtering Log Entries
Objective: Implement a log file processor that filters lines based on a dynamically specified criterion using closures.

use std::fs::File;
use std::io::{self, BufRead, BufReader};

/// Processes a log file line by line, applying a filter defined by the passed closure.
/// The closure `predicate` determines whether a line should be included in the output.
fn process_log_file<F>(file_path: &str, predicate: F) -> io::Result<Vec<String>>
where
    F: Fn(&str) -> bool,
{
    let file = File::open(file_path)?;
    let reader = BufReader::new(file);
    let mut filtered_lines = Vec::new();

    for line_result in reader.lines() {
        let line = line_result?;
        if predicate(&line) {
            filtered_lines.push(line);
        }
    }

    Ok(filtered_lines)
}

fn main() -> io::Result<()> {
    let log_path = "system.log"; // Example log file path

    // Example usage: Extract lines that contain "ERROR"
    let errors = process_log_file(log_path, |line| line.contains("ERROR"))?;
    println!("Error lines: {:?}", errors);

    // Example usage: Extract lines with "WARN" that also mention "Memory"
    let disk_warnings = process_log_file(log_path, |line| line.contains("WARN") && line.contains("Memory"))?;
    println!("Disk warning lines: {:?}", disk_warnings);

    Ok(())
}

// system.log file
// 2024-03-24 08:30:00 INFO System boot
// 2024-03-24 08:30:15 WARN Disk usage exceeds 90%
// 2024-03-24 08:30:30 INFO New user session started
// 2024-03-24 08:31:00 ERROR Network interface eth0 down
// 2024-03-24 08:32:00 INFO Network interface eth0 up
// 2024-03-24 08:33:00 INFO System update started
// 2024-03-24 08:35:00 INFO System update completed
// 2024-03-24 08:36:00 WARN Memory usage exceeds 80%

Explanation:

Flexibility with Closures: The process_log_file function is designed to be flexible, using a closure predicate that takes a string slice (a line from the log file) and returns true if the line matches the criteria of interest. This allows callers to specify exactly what they're looking for in the log file dynamically.
System Resource Efficiency: This approach reads the file line by line using a BufReader, which is efficient and suitable for large files. It avoids loading the entire file into memory, which is crucial in systems programming where resources might be limited.
Dynamic Behavior: By accepting a closure as a parameter, process_log_file can easily adapt to different needs without changing its implementation. Whether you're interested in errors, warnings, or any specific text pattern, you can define the logic at the call site.
